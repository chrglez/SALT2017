{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Comparativa de modelos de clasificación no paramétricos frente modelos de elección discreta convencionales\"\nsubtitle: \"Una aplicación con datos de percepción de factores de riesgo oncológicos\"\nauthor: \"Miguel Ángel Negrín, Jaime Pinilla, Christian González, Francisco J. Vázquez\"\naffiliation: \"Departamento de Métodos Cuantitativos en Economía y Gestión. Universidad de Las Palmas de Gran Canaria\"\ndate: \"Barcelona, 7 septiembre 2017\"\noutput:\n    revealjs::revealjs_presentation:\n        self_contained: false\n        center: TRUE\n        template: congresos.html\n        css: custom.css\n        highlight: tango\n        transition: none\n        background_transition: none\n        reveal_options:\n            progress: false\n---\n\n## Índice de contenidos\n\n- Aprendizaje automático\n- Datos\n- Análisis descriptivo\n- Resultados\n- Conclusiones\n\n## Aprendizaje automático {data-background=#005193 .white}\n\n## Aprendizaje automático\n\n- Ventajas aprendizaje automático\n    - Algoritmos computacionales que se mejoran automáticamente a través de la experiencia.\n    - Modelos no paramétricos.\n    - Pueden detectar relaciones no lineales entre las variables\n    - Tienen la habilidad de detectar todas la posibles relaciones entre las variables predictivas\n\n- Limitaciones de los modelos Logit\n    - Se asume que los individuos tienen la misma respuesta ante una variación de las explicativas\n\n    - El cociente de las probabilidades de elección de dos alternativas no depende de las restantes alternativas\n    - No se admiten correlación entre las observaciones.\n\n\n## Redes neuronales\n\n- Sistema no paramétrico que simula una red neuronal biológica.\n- Es una función matemática que obtiene una salida en función de unas entradas. Esta función se puede descomponer en diferentes funciones que representarían cada una de las capas de la red.\n- Aunque hay diferentes tipos de RNA, se trabajó con una red feedfoward donde los parámetros se ajustaron mediante aprendizaje supervisado\n- Ventajas:\n    - Habilidad de aprender mediante la etapa de aprendizaje\n    - Crea su propia representación de la información.\n- Desventajas\n    - La interpretación de los parámetros no es inmediata.\n\n---\n\n![Red neuronal](images/redes.png)\n\n## k-Nearest Neighbour\n\n\n```{r, message = FALSE, warning = FALSE, echo = FALSE}\nlibrary(rpart)\nlibrary(rattle)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(highcharter)\n```\n\n```{r, echo = FALSE}\nx <- c(1,0.5,0.8,2,1.8,2.1,3,3,3.2,3.6,4,2.5)\ny <- c(1,2,3,2.8,2.3,1.4,2.5,1.6,0.5,3.5,1.7,2.5)\ndf <- data.frame(x,y)\ndf$class <- c(\"green\",\"green\",\"green\",\"green\",\"red\",\"red\",\"green\",\"red\",\"red\",\"green\",\"red\",\"class?\")\n\ncircleFun <- function(center = c(0,0),diameter = 1, npoints = 100){\n    r = diameter / 2\n    tt <- seq(0,2*pi,length.out = npoints)\n    xx <- center[1] + r * cos(tt)\n    yy <- center[2] + r * sin(tt)\n    return(data.frame(x = xx, y = yy))\n}\n\ndat <- circleFun(c(2.5,2.5),1.7,npoints = 100)\n\nggplot(data = df, aes(x,y)) +\n      geom_point(aes(colour = class, shape = class), size = 6) +\n      geom_path(data = dat) +\n\n      scale_color_manual(name = \"\", values = c(\"blue\",\"darkgreen\", \"darkred\" )) + \n      scale_shape_manual( name = \"\", values = c(13,16,15)) +\n      annotate(geom=\"text\", x=2.5, y=1.6, label=\"k = 3\") +\n      theme_bw()\n      \n```\n\n## Naive Bayes\n\n```{r, echo=FALSE}\nset.seed(2345)\nx <- sample(seq(0,1,0.05),100,replace = TRUE)\ny <- sample(seq(0,1,0.05),100,replace = TRUE)\ndf <- data.frame(x,y)\ndf$class <- if_else( y < 0.5 | (y>=0.5 & x >= 0.5),\"red\",\"green\")\ndf <- rbind(df,c(0.2,0.75,\"class?\"))\ndf$x <- as.numeric(df$x)\ndf$y <- as.numeric(df$y)\n#hchart(df, \"scatter\", hcaes(x = x, y = y, group = class),\n#       backgroundColor = \"#D9E9FF\") %>%\n#      hc_colors(c(\"#808080\",\"#006400\",\"#8b0000\"))\nggplot(data = df, aes(x,y)) +geom_point(aes(colour = class), size = 5) + scale_color_manual(name = \"\", values = c(\"blue\",\"darkgreen\", \"darkred\")) +      theme_minimal()\n```\n\n\n## Árbol de decisión\n\n```{r, echo=FALSE}\nset.seed(1234)\nx <- sample(seq(0,1,0.05),100,replace = TRUE)\ny <- sample(seq(0,1,0.05),100,replace = TRUE)\ndf <- data.frame(x,y)\ndf$class <- if_else( y < 0.5 | (y>=0.5 & x >= 0.5),\"red\",\"green\")\nggplot(data = df, aes(x,y)) +geom_point(aes(colour = class), size = 5) + scale_color_manual(name = \"\", values = c(\"darkgreen\", \"darkred\")) +\n      theme_bw()\n```\n\n---\n\n```{r, echo = FALSE}\nfit <- rpart(class ~ x + y,\n             data=df,\n             method=\"class\")\nfancyRpartPlot(fit, sub=\"\")\n```\n\n## Random Forest\n\n![Random Forest](images/bagging.jpg) \n\n## Xgboost\n\n![Random Forest](images/bigd.png) \n\n## Cross Validation\n![Cross Validation](images/CV.png)\n\n## Hiperparámetros {.reduccion}\n![Optimización ROC](images/knnROC.png) \n\n## Datos {data-background=#005193 .white}\n\n## Datos\n\n> Sanz-Barbero, B., Prieto-Flores, M. E., Otero-García, L.,  Abt-Sacks, A., Bernal, M., & Cambas, N. (2014). Perception of risk  factors for cancer in the Spanish population. Gaceta sanitaria,  28(2), 137-145.\n\n> Analizar la percepción de la población española sobre la importancia de los factores de riesgo de cáncer.\n\n## Datos(2)\n\n- OncoBarómetro: Base de datos poblacional representativa de la población española mayor de 18 años, no institucionalizada, que recoge información sobre los conocimientos, las actitudes y las percepciones en torno al cáncer. \n\n- Diseño del cuestionario: Observatorio del Cáncer de la Asociación Española Contra el Cáncer y el Centro de Investigaciones Sociológicas (CIS). \n\n- Trabajo de campo:  noviembre y diciembre de 2010\n\n## Datos (3)\n\n![ENS](images/P10.png)\n\n\n## Análisis descriptivo {data-background=#005193 .white}\n\n## Análisis descriptivo {.reduccion}\n\n```{r echo = FALSE}\ndb_filtrada <- readr::read_rds(\"../db_filtrada.Rds\")\n```\n\n<table style=\"width:100%;\">\n<colgroup>\n<col style=\"width: 35%\" />\n<col style=\"width: 75%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Variables exógenas</th>\n<th>Atributos</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>Sexo</td>\n<td>`r levels(db_filtrada$sexo)`</td>\n</tr>\n<tr class=\"even\">\n<td>Edad</td>\n<td>`r levels(db_filtrada$edad)`</td>\n</tr>\n<tr class=\"odd\">\n<td>País</td>\n<td>`r levels(db_filtrada$pais)`</td>\n</tr>\n<tr class=\"even\">\n<td>Estudios</td>\n<td>`r levels(db_filtrada$estudios)`</td>\n</tr>\n<tr class=\"odd\">\n<td>Salud percibida</td>\n<td>`r levels(db_filtrada$saludpercibida)`</td>\n</tr>\n<tr class=\"even\">\n<td>Estilo de vida</td>\n<td>`r levels(db_filtrada$estilovida)`</td>\n</tr>\n<tr class=\"odd\">\n<td>Enfermedades cancerosas</td>\n<td>`r levels(db_filtrada$enfcancerosas)`</td>\n</tr>\n<tr class=\"even\">\n<td>Persona cercana con cancer</td>\n<td>`r levels(db_filtrada$cercanacancer)`</td>\n</tr>\n<tr class=\"odd\">\n<td>Recepción información</td>\n<td>`r levels(db_filtrada$recepcion)`</td>\n</tr>\n<tr class=\"even\">\n<td>Recomendación</td>\n<td>`r levels(db_filtrada$recomendacion)`</td>\n</tr>\n<tr class=\"odd\">\n<td>Síntomas</td>\n<td>`r levels(db_filtrada$sintomas)`</td>\n</tr>\n<tr class=\"even\">\n<td>Temor</td>\n<td>`r levels(db_filtrada$temor)`</td>\n</tr>\n<tr class=\"odd\">\n<td>Riesgo</td>\n<td>`r levels(db_filtrada$riesgo)`</td>\n</tr>\n<tr class=\"even\">\n<td>Cancer problema</td>\n<td>`r levels(db_filtrada$cancerproblema)`</td>\n</tr>\n</tbody>\n</table>\n\n\n## Análisis descriptivo (2)\n\n- Variables exógenas: Percibe [...] como factor de riesgo de padecer cancer\n    - Tabaco, alcohol, exposición al sol\n    - Dieta, peso, ETS, historial de cáncer\n    - Radiaciones, contacto con sustancias nocivas, contaminación\n\n\n<div style = \"margin:100px 0 0 0\";>\n    \n```{r, eval=FALSE}\ntabaco ~ sexo + edad + pais + estudios + saludpercibida + estilovida + enfcancerosas + cercanacancer + recepcion + recomendacion + sintomas + temor + riesgo + cancerproblema\n```\n\n</div>\n\n## Tabaco como factor de riesgo de cáncer {.h1reduccion}\n\n```{r echo = FALSE, message = FALSE, warning=FALSE}\ndb_tabaco <- db_filtrada %>% select(sexo:tabaco) %>%\n      filter(complete.cases(.))\nbaja <- round(100*prop.table(table(db_tabaco$tabaco)),2)[1]\nalta <- round(100*prop.table(table(db_tabaco$tabaco)),2)[2]\n\ndatos_graf <- purrr::map_dfr(1:14, function(ent){\n       temp <- table(db_tabaco[,ent])\n       y <- sort(as.numeric(temp)/sum(as.numeric(temp)))\n       z <- LETTERS[1:length(y)]\n       indx <- rep(ent,length(y))\n       cumpor <- sort(cumsum(y),decreasing =  FALSE)\n       data.frame(por  = y, cumpor = cumpor,  atributos = z, indx = indx )\n})\n\ndatos_graf$variable <- names(db_tabaco)[datos_graf$indx]\ndatos_graf$variable <- factor(datos_graf$variable,levels = names(db_tabaco)[1:14])\ndatos_graf$atributos <- factor(datos_graf$atributos, levels = LETTERS[1:4])\nggplot(datos_graf,aes(x = variable, y = por, fill = atributos)) + \n      geom_col(colour=\"black\") +\n      geom_text(aes(label = scales::percent(por)),\n               position = position_stack(vjust = 0.5)) +\n      scale_y_continuous(labels = scales::percent) +\n      labs(x=\"\",y=\"\") +\n      theme_minimal() +\n      theme(legend.position = \"none\",\n            axis.text.x = element_text(angle = 45, hjust = 1)) +\n      scale_fill_brewer()\n\n```\n\n---\n\n```{r echo = FALSE, message = FALSE, warning=FALSE}\ndatos_graf2 <- purrr::map_dfr(1:14, function(ent){\n      temp <- table(db_tabaco[,ent])\n      z <-dimnames(temp)[[1]]\n      \n      y <- purrr::map_dbl(z, function(pas){\n             temp <- db_tabaco %>% filter(db_tabaco[,ent] == pas)\n             sum(temp$tabaco == \"alta\")/nrow(temp)\n             })\n\n      indx <- rep(ent,length(y))\n\n      data.frame(por  = y,  atributos = z, indx = indx )\n      \n})\n\ndatos_graf2$variable <- names(db_tabaco)[datos_graf2$indx]\ndatos_graf2$ejex <- datos_graf2$atributos\nindice <- datos_graf2$atributos ==\"Sí\" | datos_graf2$atributos == \"No\"\ndatos_graf2$ejex[indice] <- \n      paste0(datos_graf2$atributos[indice],\"/\",datos_graf2$variable[indice])\ndatos_graf2$ejex <- factor(datos_graf2$ejex,levels = datos_graf2$ejex )\n\npunto_corte <- sum(db_tabaco$tabaco == \"alta\")/length(db_tabaco$tabaco)\n\n\nggplot(datos_graf2,aes(x = ejex, y = por)) + \n      geom_col(colour=\"black\", fill = \"#005193\") +\n      geom_text(aes(label = scales::percent(por), y = 0.1), angle = 90, colour = \"white\") +\n      scale_y_continuous(labels = scales::percent) +\n      labs(x=\"\",y=\"\", subtitle = paste0(\"Frecuencia = \",round(punto_corte,2))) +\n      theme_minimal() +\n      theme(legend.position = \"none\",\n            axis.text.x = element_text(angle = 45, hjust = 1)) +\n      scale_fill_brewer()\n\n\n```\n\n## Resultados {data-background=#005193 .white}\n\n\n## Resultados\n\n```{r, echo=FALSE, message=FALSE,warning=FALSE}\nlibrary(purrr)\nlibrary(knitr)\nlibrary(kableExtra)\ncm <- readr::read_rds(\"../cm.Rds\")\n\nresultados <- map_df(cm, function(x){\n      precision <- round(as.numeric(x$overall[1]),4)\n      sensibilidad <- round(as.numeric(x$byClass[1]),4)\n      especificidad <- round(as.numeric(x$byClass[2]),4)\n      data.frame(precision, sensibilidad, especificidad)\n})\n\nresultados <- resultados %>%\n      mutate(Algoritmo = c(\"Logística\",\"ANN\",\"KNN\",\"Naive Bayes\",\"Random Forest\", \"XGBoost\")) %>%\n      select(Algoritmo,precision:especificidad) %>%\n      set_names(c(\"Algoritmo\",\"Precisión\",\"Sensibilidad\",\"Especificidad\"))\n\nresultados$AUC <- round(readr::read_rds(\"auc_values.Rds\"),4)\nresultados$AUC[1] <- 0.5314\n\nkable(resultados) %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n```\n\n## Significación variables LOGIT\n\n```{r, echo = FALSE, message=FALSE, warning=FALSE}\nsig <- readr::read_rds(\"significacion.Rds\")\nkable(sig) %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n```\n\n\n\n\n## Importancia variables NN {.reduccion}\n![Importancia variables NN](images/vinn.png) \n\n\n\n## Importancia variables RF {.reduccion}\n![Importancia variables RF](images/varImprf.png) \n\n## Importancia variables XGBoost\n\n![Importancia variables XGBoost](images/vixgboost.jpg)\n\n## Clases desbalanceadas\n\n- Ponderar las clases\n- Down-sampling\n- Up-sampling\n\n\n## Curvas ROC\n\n![Curvas ROC](images/ROC.png) \n\n\n\n\n## Conclusiones {data-background=#005193 .white}\n\n## Conclusiones \n\n- Se presentarosn 5 modelos basados en el aprendizaje automático\n    - Redes Neuronales\n    - K-nearest neighbours\n    - Naive Bayes\n    - Random Forest\n    - XGBoost\n\n- Estos algoritmos superan al modelo de elección discreta Logit en términos de precisión y AUC\n\n- Los modelos basados en el aprendizaje automático permiten la computación en paralelo por lo que son rápidos a la hora de manejar gran cantidad de datos. \n    \n\n## Comparativa de modelos de clasificación no paramétricos frente modelos de elección discreta convencionales {data-background=#005193 .white}\n\n\n\n```\n\n\n\n",
    "created" : 1508825796564.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "293748558",
    "id" : "30708D45",
    "lastKnownWriteTime" : 1504767685,
    "last_content_update" : 1504767685,
    "path" : "C:/Users/arama/Dropbox/170908 AES BArcelona/Machine Learning/presentacion/170907 presentacion barcelona AESv2.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}